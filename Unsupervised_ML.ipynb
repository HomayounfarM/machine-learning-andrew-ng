{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMGQO9py4/tp1tvWNBX4OgS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HomayounfarM/machine-learning-andrew-ng/blob/main/Unsupervised_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#K-mean"
      ],
      "metadata": {
        "id": "hPRIpNAfsBPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1: Import libraries"
      ],
      "metadata": {
        "id": "qhQ6rJs53xNi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6nuJZYK3Yf-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2: Generate random data\n",
        "\n",
        "Here is the code for generating some random data in a two-dimensional space:"
      ],
      "metadata": {
        "id": "XEv7vq8c3tGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A total of 100 data points has been generated and divided into two groups, of 50 points each.\n",
        "\n",
        "Here is how the data is displayed on a two-dimensional space:"
      ],
      "metadata": {
        "id": "vke3y5q86-fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X= -2 * np.random.rand(100,2)\n",
        "X1 = 2 + 1* np.random.rand(20,2)\n",
        "X2 = 6 + 1* np.random.rand(20,2)\n",
        "X3 = 4 + 1* np.random.rand(20,2)\n",
        "X4 = 9 - 1* np.random.rand(20,2)\n",
        "X[20:40, :] = X1\n",
        "X[40:60, :] = X2\n",
        "X[60:80, :] = X3\n",
        "X[80:100, :] = X4\n",
        "plt.scatter(X[ : , 0], X[ :, 1], s = 50,  c= \"r\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qS5FgSPp3qrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3: Use Scikit-Learn\n",
        "\n",
        "We’ll use some of the available functions in the Scikit-learn library to process the randomly generated data.\n",
        "\n",
        "Here is the code:"
      ],
      "metadata": {
        "id": "zIhV48Da66wX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "list = []\n",
        "\n",
        "for i in range(6):\n",
        "  Kmean = KMeans(n_clusters=i+1)\n",
        "  Kmean.fit(X)\n",
        "  list.append(Kmean.cluster_centers_)\n",
        "\n",
        "list\n"
      ],
      "metadata": {
        "id": "PcUcaMmI40T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list[5][:,0]"
      ],
      "metadata": {
        "id": "qPcEQfvTIGK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[ : , 0], X[ :, 1], s = 50,  c= \"r\")\n",
        "\n",
        "plt.scatter(list[5][:,0], list[5][:,1], color='b')"
      ],
      "metadata": {
        "id": "AEN-RRTZHzGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, we arbitrarily gave k (n_clusters) an arbitrary value of two.\n",
        "\n",
        "Here is the output of the K-means parameters we get if we run the code:"
      ],
      "metadata": {
        "id": "tsc5pAYN7Ls3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300, n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001, verbose=0)"
      ],
      "metadata": {
        "id": "m3mnBRiB7NOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Finding the centroid\n",
        "\n",
        "Here is the code for finding the center of the clusters:"
      ],
      "metadata": {
        "id": "pjsJMSkQ7S0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Kmean.cluster_centers_"
      ],
      "metadata": {
        "id": "XkLw8SZp7UVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s display the cluster centroids (using green and red color)."
      ],
      "metadata": {
        "id": "v3y592lQ7XH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[ : , 0], X[ : , 1], s =50, c='b')\n",
        "plt.scatter(-0.94665068, -0.97138368, s=200, c='g', marker='s')\n",
        "plt.scatter(2.01559419, 2.02597093, s=200, c='r', marker='s')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "egsDdNjw7aIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 5: Testing the algorithm\n",
        "\n",
        "Here is the code for getting the labels property of the K-means clustering example dataset; that is, how the data points are categorized into the two clusters."
      ],
      "metadata": {
        "id": "jHVcSdPX7e9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Kmean.labels_"
      ],
      "metadata": {
        "id": "wQc9rkgL7hg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see above, 50 data points belong to the 0 cluster while the rest belong to the 1 cluster.\n",
        "\n",
        "For example, let’s use the code below for predicting the cluster of a data point:"
      ],
      "metadata": {
        "id": "HQ3kjLWA7lkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_test=np.array([-3.0,-3.0])\n",
        "second_test=sample_test.reshape(1, -1)\n",
        "Kmean.predict(second_test)"
      ],
      "metadata": {
        "id": "tadCt62L7oNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It shows that the test data point belongs to the 0 (green centroid) cluster.\n",
        "\n",
        "Wrapping up\n",
        "Here is the entire K-means clustering algorithm code in Python:"
      ],
      "metadata": {
        "id": "Qz278Bq57wEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "%matplotlib inline\n",
        "X= -2 * np.random.rand(100,2)\n",
        "X1 = 1 + 2 * np.random.rand(50,2)\n",
        "X[50:100, :] = X1\n",
        "plt.scatter(X[ : , 0], X[ :, 1], s = 50, c = 'b')\n",
        "plt.show()\n",
        "from sklearn.cluster import KMeans\n",
        "Kmean = KMeans(n_clusters=2)\n",
        "Kmean.fit(X)\n",
        "Kmean.cluster_centers_\n",
        "plt.scatter(X[ : , 0], X[ : , 1], s =50, c='b')\n",
        "plt.scatter(-0.94665068, -0.97138368, s=200, c='g', marker='s')\n",
        "plt.scatter(2.01559419, 2.02597093, s=200, c='r', marker='s')\n",
        "plt.show()\n",
        "Kmean.labels_\n",
        "sample_test=np.array([-3.0,-3.0])\n",
        "second_test=sample_test.reshape(1, -1)\n",
        "Kmean.predict(second_test)"
      ],
      "metadata": {
        "id": "o-zOKj0s7yQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-means clustering is an extensively used technique for data cluster analysis.\n",
        "\n",
        "It is easy to understand, especially if you accelerate your learning using a K-means clustering tutorial. Furthermore, it delivers training results quickly.\n",
        "\n",
        "However, its performance is usually not as competitive as those of the other sophisticated clustering techniques because slight variations in the data could lead to high variance.\n",
        "\n",
        "Furthermore, clusters are assumed to be spherical and evenly sized, something which may reduce the accuracy of the K-means clustering Python results.\n",
        "\n",
        "What’s your experience with K-means clustering in machine learning?\n",
        "\n",
        "Please share your comments below."
      ],
      "metadata": {
        "id": "00hsZHMf72mr"
      }
    }
  ]
}