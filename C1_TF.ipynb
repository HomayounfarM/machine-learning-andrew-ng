{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNy95cTSBBUNMgo6cUGk8R3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HomayounfarM/machine-learning-andrew-ng/blob/main/C1_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Czo72sRgT6Z5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import math\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eqpxGPoUWKmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = '/content/drive/My Drive/Colab Notebooks/Data/ex2data1.csv'\n",
        "df = pd.read_csv(url, header=None)\n",
        "df.columns = ['X1', 'X2', 'Y']\n",
        "df"
      ],
      "metadata": {
        "id": "UyLkwac3ZKwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "X_train = np.array(df[['X1', 'X2']])\n",
        "y_train = np.array(df['Y'])"
      ],
      "metadata": {
        "id": "bdMf4GDNURCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First five elements in X_train are:\\n\", X_train[:5])\n",
        "print(\"Type of X_train:\",type(X_train))"
      ],
      "metadata": {
        "id": "xqu4WWf8gk0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First five elements in y_train are:\\n\", y_train[:5])\n",
        "print(\"Type of y_train:\",type(y_train))"
      ],
      "metadata": {
        "id": "_A7LcCFQhDdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('The shape of X_train is: ' + str(X_train.shape))\n",
        "print ('The shape of y_train is: ' + str(y_train.shape))\n",
        "print ('We have m = %d training examples' % (len(y_train)))"
      ],
      "metadata": {
        "id": "J6SUYVvNhGbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = df['X1']\n",
        "x2 = df['X2']\n",
        "y = df['Y']\n",
        "\n",
        "plt.scatter(x1[y==0], x2[y==0], s=3, c='r')\n",
        "plt.scatter(x1[y==1], x2[y==1], s=3, c='b')"
      ],
      "metadata": {
        "id": "hTNnKBsntbaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sigmoid function"
      ],
      "metadata": {
        "id": "ZTUsAQkZtXjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C1\n",
        "# GRADED FUNCTION: sigmoid\n",
        "\n",
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Compute the sigmoid of z\n",
        "\n",
        "    Args:\n",
        "        z (ndarray): A scalar, numpy array of any size.\n",
        "\n",
        "    Returns:\n",
        "        g (ndarray): sigmoid(z), with the same shape as z\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    g = 1/(1+np.exp(-z))\n",
        "    ### END SOLUTION ###\n",
        "\n",
        "    return g"
      ],
      "metadata": {
        "id": "13qzogychNLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"sigmoid(0) = \" + str(sigmoid(0)))"
      ],
      "metadata": {
        "id": "eHlNXYUziRvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C2\n",
        "# GRADED FUNCTION: compute_cost\n",
        "def compute_cost(X, y, w, b, lambda_= 1):\n",
        "    \"\"\"\n",
        "    Computes the cost over all examples\n",
        "    Args:\n",
        "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
        "      y : (array_like Shape (m,)) target value\n",
        "      w : (array_like Shape (n,)) Values of parameters of the model\n",
        "      b : scalar Values of bias parameter of the model\n",
        "      lambda_: unused placeholder\n",
        "    Returns:\n",
        "      total_cost: (scalar)         cost\n",
        "    \"\"\"\n",
        "\n",
        "    m, n = X.shape\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    z = X.dot(w)+b\n",
        "    f = sigmoid(z)\n",
        "    total_cost = (1/m) * (-y.T.dot(np.log(f))- (1-y).T.dot(np.log(1-f)))\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return total_cost"
      ],
      "metadata": {
        "id": "-_4oU_vWiWPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m, n = X_train.shape\n",
        "\n",
        "# Compute and display cost with w initialized to zeroes\n",
        "initial_w = np.zeros(n)\n",
        "initial_b = 0.\n",
        "cost = compute_cost(X_train, y_train, initial_w, initial_b)\n",
        "print('Cost at initial w (zeros): {:.3f}'.format(cost))"
      ],
      "metadata": {
        "id": "rr-vRsnyio_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C3\n",
        "# GRADED FUNCTION: compute_gradient\n",
        "def compute_gradient(X, y, w, b, lambda_=None):\n",
        "    \"\"\"\n",
        "    Computes the gradient for logistic regression\n",
        "\n",
        "    Args:\n",
        "      X : (ndarray Shape (m,n)) variable such as house size\n",
        "      y : (array_like Shape (m,1)) actual value\n",
        "      w : (array_like Shape (n,1)) values of parameters of the model\n",
        "      b : (scalar)                 value of parameter of the model\n",
        "      lambda_: unused placeholder.\n",
        "    Returns\n",
        "      dj_dw: (array_like Shape (n,1)) The gradient of the cost w.r.t. the parameters w.\n",
        "      dj_db: (scalar)                The gradient of the cost w.r.t. the parameter b.\n",
        "    \"\"\"\n",
        "    m, n = X.shape\n",
        "    dj_dw = np.zeros(w.shape)\n",
        "    dj_db = 0.\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    y = y.reshape(-1,1)\n",
        "    w = w.reshape(-1,1)\n",
        "\n",
        "    f = sigmoid(X.dot(w)+b)\n",
        "    diff_fy = f-y\n",
        "    dj_dww = (1/m) * diff_fy.T.dot(X)\n",
        "    dj_dww = dj_dww.T\n",
        "    dj_dw = np.reshape(dj_dww, -1)\n",
        "    dj_db = (1/m) * (dj_db + np.sum(diff_fy))\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return dj_db, dj_dw"
      ],
      "metadata": {
        "id": "yNNyxraOv0ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and display gradient with w initialized to zeroes\n",
        "initial_w = np.zeros(n)\n",
        "initial_b = 0.\n",
        "\n",
        "dj_db, dj_dw = compute_gradient(X_train, y_train, initial_w, initial_b)\n",
        "print(f'dj_db at initial w (zeros):{dj_db}' )\n",
        "print(f'dj_dw at initial w (zeros):{dj_dw.tolist()}' )"
      ],
      "metadata": {
        "id": "nU6qX0Tzv_zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute and display cost and gradient with non-zero w\n",
        "test_w = np.array([ 0.2, -0.5])\n",
        "test_b = -24\n",
        "dj_db, dj_dw  = compute_gradient(X_train, y_train, test_w, test_b)\n",
        "\n",
        "print('dj_db at test_w:', dj_db)\n",
        "print('dj_dw at test_w:', dj_dw.tolist())\n",
        "\n"
      ],
      "metadata": {
        "id": "VMiU6tv7wD5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters, lambda_):\n",
        "    \"\"\"\n",
        "    Performs batch gradient descent to learn theta. Updates theta by taking\n",
        "    num_iters gradient steps with learning rate alpha\n",
        "\n",
        "    Args:\n",
        "      X :    (array_like Shape (m, n)\n",
        "      y :    (array_like Shape (m,))\n",
        "      w_in : (array_like Shape (n,))  Initial values of parameters of the model\n",
        "      b_in : (scalar)                 Initial value of parameter of the model\n",
        "      cost_function:                  function to compute cost\n",
        "      alpha : (float)                 Learning rate\n",
        "      num_iters : (int)               number of iterations to run gradient descent\n",
        "      lambda_ (scalar, float)         regularization constant\n",
        "\n",
        "    Returns:\n",
        "      w : (array_like Shape (n,)) Updated values of parameters of the model after\n",
        "          running gradient descent\n",
        "      b : (scalar)                Updated value of parameter of the model after\n",
        "          running gradient descent\n",
        "    \"\"\"\n",
        "\n",
        "    # number of training examples\n",
        "    m = len(X)\n",
        "\n",
        "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
        "    J_history = []\n",
        "    w_history = []\n",
        "\n",
        "    for i in range(num_iters):\n",
        "\n",
        "        # Calculate the gradient and update the parameters\n",
        "        dj_db, dj_dw = gradient_function(X, y, w_in, b_in, lambda_)\n",
        "\n",
        "        # Update Parameters using w, b, alpha and gradient\n",
        "        w_in = w_in - alpha * dj_dw\n",
        "        b_in = b_in - alpha * dj_db\n",
        "\n",
        "        # Save cost J at each iteration\n",
        "        if i<100000:      # prevent resource exhaustion\n",
        "            cost =  cost_function(X, y, w_in, b_in, lambda_)\n",
        "            J_history.append(cost)\n",
        "\n",
        "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
        "        if i% math.ceil(num_iters/10) == 0 or i == (num_iters-1):\n",
        "            w_history.append(w_in)\n",
        "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}   \")\n",
        "\n",
        "    return w_in, b_in, J_history, w_history #return w and J,w history for graphing"
      ],
      "metadata": {
        "id": "KCwRz6UcwQkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "intial_w = 0.01 * (np.random.rand(2).reshape(-1,1) - 0.5)\n",
        "initial_b = -8\n",
        "\n",
        "\n",
        "# Some gradient descent settings\n",
        "iterations = 10000\n",
        "alpha = 0.001\n",
        "\n",
        "w,b, J_history,_ = gradient_descent(X_train ,y_train, initial_w, initial_b,\n",
        "                                   compute_cost, compute_gradient, alpha, iterations, 0)\n",
        "b"
      ],
      "metadata": {
        "id": "rB7CX92RwUl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_temp = np.linspace(min(x1), max(x1), num=len(x1))\n",
        "y_predicted = -(w[1]*x_temp+b)/w[0]"
      ],
      "metadata": {
        "id": "FjwxIr4MHpLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plotting the decision boundary\n",
        "\n",
        "Try to plot decision boundary from got in previous step."
      ],
      "metadata": {
        "id": "vRhRigRDwxvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = df['X1']\n",
        "x2 = df['X2']\n",
        "y = df['Y']\n",
        "\n",
        "plt.scatter(x1[y==0], x2[y==0], s=3, c='r')\n",
        "plt.scatter(x1[y==1], x2[y==1], s=3, c='b')\n",
        "\n",
        "#add line to show fitted polynomial regression model\n",
        "plt.plot(x_temp, y_predicted, color='purple')"
      ],
      "metadata": {
        "id": "NyY2fPNDHHTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C4\n",
        "# GRADED FUNCTION: predict\n",
        "\n",
        "def predict(X, w, b):\n",
        "    \"\"\"\n",
        "    Predict whether the label is 0 or 1 using learned logistic\n",
        "    regression parameters w\n",
        "\n",
        "    Args:\n",
        "    X : (ndarray Shape (m, n))\n",
        "    w : (array_like Shape (n,))      Parameters of the model\n",
        "    b : (scalar, float)              Parameter of the model\n",
        "\n",
        "    Returns:\n",
        "    p: (ndarray (m,1))\n",
        "        The predictions for X using a threshold at 0.5\n",
        "    \"\"\"\n",
        "    # number of training examples\n",
        "    m, n = X.shape\n",
        "    p = np.zeros(m)\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    z = X.dot(w)+b\n",
        "    f = sigmoid(z)\n",
        "    p = f >= 0.5\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return p"
      ],
      "metadata": {
        "id": "d8cntdSwxD0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your predict code\n",
        "np.random.seed(1)\n",
        "tmp_w = np.random.randn(2)\n",
        "tmp_b = 0.3\n",
        "tmp_X = np.random.randn(4, 2) - 0.5\n",
        "\n",
        "tmp_p = predict(tmp_X, tmp_w, tmp_b)\n",
        "print(f'Output of predict: shape {tmp_p.shape}, value {tmp_p}')"
      ],
      "metadata": {
        "id": "WDd_uPArxIql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute accuracy on our training set\n",
        "p = predict(X_train, w,b)\n",
        "print('Train Accuracy: %f'%(np.mean(p == y_train) * 100))"
      ],
      "metadata": {
        "id": "A0OySDpLxPOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Regularized Logistic Regression"
      ],
      "metadata": {
        "id": "pIqgggnHxSMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = '/content/drive/My Drive/Colab Notebooks/Data/ex2data2.csv'\n",
        "df = pd.read_csv(url, header=None)\n",
        "df.columns = ['X1', 'X2', 'Y']\n",
        "df"
      ],
      "metadata": {
        "id": "lQ-KsCBvxcwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "X_train = np.array(df[['X1', 'X2']])\n",
        "y_train = np.array(df['Y'])"
      ],
      "metadata": {
        "id": "prPGhqXyDX-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = df['X1']\n",
        "x2 = df['X2']\n",
        "y = df['Y']\n",
        "\n",
        "plt.scatter(x1[y==0], x2[y==0], s=3, c='r')\n",
        "plt.scatter(x1[y==1], x2[y==1], s=3, c='b')"
      ],
      "metadata": {
        "id": "WTwXjfx3y6T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_feature(X, Y):\n",
        "  # demonstrate the types of features created\n",
        "  import numpy as np\n",
        "  from sklearn.preprocessing import PolynomialFeatures\n",
        "  # define the dataset\n",
        "  data = np.vstack([X,Y]).T\n",
        "  # perform a polynomial features transform of the dataset\n",
        "  poly = PolynomialFeatures(degree=6, include_bias=False)\n",
        "  data = poly.fit_transform(data)\n",
        "  return data"
      ],
      "metadata": {
        "id": "wy-McGnM3-EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original shape of data:\", X_train.shape)\n",
        "\n",
        "mapped_X =  map_feature(X_train[:, 0], X_train[:, 1])\n",
        "print(\"Shape after feature mapping:\", mapped_X.shape)"
      ],
      "metadata": {
        "id": "Sm97uDXIBRSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train[0]:\", X_train[0])\n",
        "print(\"mapped X_train[0]:\", mapped_X[0])"
      ],
      "metadata": {
        "id": "ueck5DJAC108"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C5\n",
        "def compute_cost_reg(X, y, w, b, lambda_ = 1):\n",
        "    \"\"\"\n",
        "    Computes the cost over all examples\n",
        "    Args:\n",
        "      X : (array_like Shape (m,n)) data, m examples by n features\n",
        "      y : (array_like Shape (m,)) target value\n",
        "      w : (array_like Shape (n,)) Values of parameters of the model\n",
        "      b : (array_like Shape (n,)) Values of bias parameter of the model\n",
        "      lambda_ : (scalar, float)    Controls amount of regularization\n",
        "    Returns:\n",
        "      total_cost: (scalar)         cost\n",
        "    \"\"\"\n",
        "\n",
        "    m, n = X.shape\n",
        "\n",
        "    # Calls the compute_cost function that you implemented above\n",
        "    cost_without_reg = compute_cost(X, y, w, b)\n",
        "\n",
        "    # You need to calculate this value\n",
        "    reg_cost = 0.\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    reg_cost = np.sum(w**2)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # Add the regularization cost to get the total cost\n",
        "    total_cost = cost_without_reg + (lambda_/(2 * m)) * reg_cost\n",
        "\n",
        "    return total_cost"
      ],
      "metadata": {
        "id": "TEOSoL2oDhZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_mapped = map_feature(X_train[:, 0], X_train[:, 1])\n",
        "np.random.seed(1)\n",
        "initial_w = np.random.rand(X_mapped.shape[1]) - 0.5\n",
        "initial_b = 0.5\n",
        "lambda_ = 0.5\n",
        "cost = compute_cost_reg(X_mapped, y_train, initial_w, initial_b, lambda_)\n",
        "\n",
        "print(\"Regularized cost :\", cost)"
      ],
      "metadata": {
        "id": "X4t6Huy-Dkdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNQ_C6\n",
        "def compute_gradient_reg(X, y, w, b, lambda_ = 1):\n",
        "    \"\"\"\n",
        "    Computes the gradient for linear regression\n",
        "\n",
        "    Args:\n",
        "      X : (ndarray Shape (m,n))   variable such as house size\n",
        "      y : (ndarray Shape (m,))    actual value\n",
        "      w : (ndarray Shape (n,))    values of parameters of the model\n",
        "      b : (scalar)                value of parameter of the model\n",
        "      lambda_ : (scalar,float)    regularization constant\n",
        "    Returns\n",
        "      dj_db: (scalar)             The gradient of the cost w.r.t. the parameter b.\n",
        "      dj_dw: (ndarray Shape (n,)) The gradient of the cost w.r.t. the parameters w.\n",
        "\n",
        "    \"\"\"\n",
        "    m, n = X.shape\n",
        "\n",
        "    dj_db, dj_dw = compute_gradient(X, y, w, b)\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    dj_dw = dj_dw + (lambda_/m) * w\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return dj_db, dj_dw"
      ],
      "metadata": {
        "id": "XHtMmwDQDoSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_mapped = map_feature(X_train[:, 0], X_train[:, 1])\n",
        "np.random.seed(1)\n",
        "initial_w  = np.random.rand(X_mapped.shape[1]) - 0.5\n",
        "initial_b = 0.5\n",
        "\n",
        "lambda_ = 0.5\n",
        "dj_db, dj_dw = compute_gradient_reg(X_mapped, y_train, initial_w, initial_b, lambda_)\n",
        "\n",
        "print(f\"dj_db: {dj_db}\", )\n",
        "print(f\"First few elements of regularized dj_dw:\\n {dj_dw[:4].tolist()}\", )"
      ],
      "metadata": {
        "id": "9UlaTclHDsSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize fitting parameters\n",
        "np.random.seed(1)\n",
        "initial_w = np.random.rand(X_mapped.shape[1])-0.5\n",
        "initial_b = 1.\n",
        "\n",
        "# Set regularization parameter lambda_ to 1 (you can try varying this)\n",
        "lambda_ = 0.01;\n",
        "# Some gradient descent settings\n",
        "iterations = 10000\n",
        "alpha = 0.01\n",
        "\n",
        "w,b, J_history,_ = gradient_descent(X_mapped, y_train, initial_w, initial_b,\n",
        "                                    compute_cost_reg, compute_gradient_reg,\n",
        "                                    alpha, iterations, lambda_)"
      ],
      "metadata": {
        "id": "IeVCC4lLDwJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plotting the decision boundary\n",
        "\n",
        "Try to plot decision boundary from got in previous step."
      ],
      "metadata": {
        "id": "F_YLlsVHEB2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute accuracy on the training set\n",
        "p = predict(X_mapped, w, b)\n",
        "\n",
        "print('Train Accuracy: %f'%(np.mean(p == y_train) * 100))"
      ],
      "metadata": {
        "id": "pt5zMimbEBbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_temp = np.linspace(min(x1), max(x1), num=len(x1))\n",
        "y_predicted = -(w[1]*x_temp+b)/w[0]"
      ],
      "metadata": {
        "id": "L5dVAyk1Mdsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = df['X1']\n",
        "x2 = df['X2']\n",
        "y = df['Y']\n",
        "\n",
        "plt.scatter(x1[y==0], x2[y==0], s=3, c='r')\n",
        "plt.scatter(x1[y==1], x2[y==1], s=3, c='b')\n",
        "\n",
        "#add line to show fitted polynomial regression model\n",
        "plt.plot(x_temp, y_predicted, color='purple')"
      ],
      "metadata": {
        "id": "9ZYhwVIJMmeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MNuiOAbPjIQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# These are the functions we use above:"
      ],
      "metadata": {
        "id": "h5wNTy3VUGmU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vJe9xAbvULgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further examples:\n",
        "https://stackoverflow.com/questions/71795205/how-to-plot-the-decision-boundary-of-a-polynomial-logistic-regression-in-python"
      ],
      "metadata": {
        "id": "rEmRNIkGNabF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def PolyCoefficients(x, coeffs):\n",
        "    \"\"\" Returns a polynomial for ``x`` values for the ``coeffs`` provided.\n",
        "\n",
        "    The coefficients must be in ascending order (``x**0`` to ``x**o``).\n",
        "    \"\"\"\n",
        "    o = len(coeffs)\n",
        "    print(f'# This is a polynomial of order {o}.')\n",
        "    y = 0\n",
        "    for i in range(o):\n",
        "        y += coeffs[i]*x**i\n",
        "    return y\n",
        "\n",
        "x = np.linspace(0, 9, 10)\n",
        "coeffs = [1, 2, 3, 4, 5]\n",
        "plt.plot(x, PolyCoefficients(x, coeffs))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nZmtMDBFPr6h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}